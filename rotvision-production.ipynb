{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_ROTATE = -1\n",
    "NUMBER_CLASSES = 4\n",
    "\n",
    "def correct_image(image, rot_correction):\n",
    "    if rot_correction == NOT_ROTATE:\n",
    "        return image\n",
    "    else:\n",
    "        return cv2.rotate(image, rot_correction)    \n",
    "    \n",
    "def preprocess(X, Y):\n",
    "    \"\"\"X: list of images\n",
    "       Y: simple list of numbers\"\"\"\n",
    "    #X =X.astype('float32')\n",
    "    #X /= 255\n",
    "    Y = np.array(Y)\n",
    "    Y = Y.reshape(len(Y), 1)\n",
    "    Y = keras.utils.to_categorical(Y, NUMBER_CLASSES)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def rot_corrections(label_code):\n",
    "    if label_code == 0:\n",
    "        return cv2.ROTATE_90_CLOCKWISE\n",
    "    elif label_code == 1:\n",
    "        return cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "    elif label_code == 2:\n",
    "        return NOT_ROTATE\n",
    "    elif label_code == 3:\n",
    "        return cv2.ROTATE_180\n",
    "\n",
    "def labels_toonehot(label):\n",
    "    if label == 'rotated_left':\n",
    "        return 0\n",
    "    elif label == 'rotated_right':\n",
    "        return 1\n",
    "    elif label == 'upright':\n",
    "        return 2\n",
    "    elif label == 'upside_down':\n",
    "        return 3\n",
    "#[1., 0., 0., 0.] - 'rotated_left'\n",
    "#[0., 1., 0., 0.] - 'rotated_right'\n",
    "#[0., 0., 1., 0.] - 'upright'\n",
    "#[0., 0., 0., 1.] - 'upside_down'\n",
    "#['rotated_left', 'rotated_right', 'upright', 'upside_down']    \n",
    "\n",
    "\n",
    "\n",
    "def prediction(file_list):\n",
    "    data_xi = load_data(file_list)\n",
    "    ypred_i = loaded_model.predict(data_xi)\n",
    "    ypred_i = np.argmax(ypred_i, axis=1)\n",
    "    return ypred_i\n",
    "    \n",
    "\n",
    "def load_data(file_list, to_preprocess = True):\n",
    "    DATA_FOLDER = 'train'\n",
    "    data = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(DATA_FOLDER, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        if to_preprocess:\n",
    "            image = preprocess(image)\n",
    "        data.append(image)\n",
    "\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.resize(image, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    return image\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'rotvision_trained_model.h5'\n",
    "\n",
    "# load json and create model\n",
    "model_json_path = os.path.join(save_dir, model_name.split('.')[0] + '.json')\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "json_file = open(model_json_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_path)\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)  # 2.2.0 to 2.3.1  --> lr changed to learning_rate\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])    \n",
    "\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a validacao aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('train.truth.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_files = labels.fn.tolist()[34227:]\n",
    "validation_labels = labels.label.tolist()[34227:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batchi = load_data(validation_files[:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = loaded_model.predict(val_batchi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.argmax(ypred,axis=1)\n",
    "truth1 = validation_labels[:32]\n",
    "truth1 = [labels_toonehot(x) for x in validation_labels[:32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertos = []\n",
    "for pred, truth in zip(pred1, truth1):\n",
    "    if pred == truth:\n",
    "        acertos.append(1)\n",
    "    else:\n",
    "        acertos.append(0)\n",
    "np.mean(acertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "number_batches = int(len(validation_files) / batch_size) + 1\n",
    "for i in range(number_batches):\n",
    "    start = i* batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    files_i = validation_files[start:end]\n",
    "    data_xi = load_data(files_i)\n",
    "    ypred_i = loaded_model.predict(data_xi)\n",
    "    ypred_i = np.argmax(ypred_i,axis=1)\n",
    "    labels_i = [labels_toonehot(x) for x in validation_labels[start:end]]\n",
    "\n",
    "    for truth, pred in zip(labels_i, ypred_i):\n",
    "        if pred == truth:\n",
    "            acertos.append(1)\n",
    "        else:\n",
    "            acertos.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 3, 3, 1, 2, 1, 2, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = load_data(validation_files[:32], False)\n",
    "labels_i = prediction(validation_files[:32])\n",
    "corrections = [rot_corrections(x) for x in labels_i]\n",
    "for i in range(32):\n",
    "    image = original_images[i]\n",
    "    cv2.imwrite(str(i) + '.jpg', image)\n",
    "    image_corr = correct_image(image, corrections[i])\n",
    "    cv2.imwrite(str(i) + '-corr.jpg', image_corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
